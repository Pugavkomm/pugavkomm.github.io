# Articles
***
* [M. M. Pugavko, O. V. Maslennikov, V. I. Nekorkin1,2 Динамика сети дискретных модельных нейронов при контролируемом обучении системы резервуарных вычислений. — Известия вузов. ПНД. 2020. Т. 28, вып. 1. С. 77-89, 2020, том 28, № 1, С. 77-89](https://andjournal.sgu.ru/ru/articles/dinamika-seti-diskretnyh-modelnyh-neyronov-pri-kontroliruemom-obuchenii-sistemy)

<details>
    <summary> Abstract </summary>

The purpose of this work is to develop a reservoir computing system that contains a network of model neurons
with discrete time, and to study the characteristics of the system when it is trained to autonomously generate a harmonic
target signal. Methods of work include approaches of nonlinear dynamics (phase space analysis depending on parameters),
machine learning (reservoir computing, supervised error minimization) and computer modeling (implementation of numerical
algorithms, plotting of characteristics and diagrams). Results. A reservoir computing system based on a network of coupled
discrete model neurons was constructed, and the possibility of its supervised training in generating the target signal using
the controlled error minimization method FORCE was demonstrated. It has been found that with increasing network size,
the mean square error of learning decreases. The dynamic regimes arising at the level of individual activity of intra-reservoir
neurons at various stages of training are studied. It is shown that in the process of training, the network-reservoir transits
from the state of space-time disorder to the state with regular clusters of spiking activity. The optimal values of the coupling
coefficients and the parameters of the intrinsic dynamics of neurons corresponding to the minimum learning error were found.
Conclusion. A new reservoir computing system is proposed in the work, the basic unit of which is the Courbage–Nekorkin
discrete-time model neuron. The advantage of a network based on such a spiking neuron model is that the model is specified
in the form of a mapping, therefore, there is no need to perform an integration operation. The proposed system has shown its
effectiveness in training autonomous generation of a harmonic function, as well as for a number of other target functions.
</details>

* [Mechislav M.Pugavko, Oleg V.Maslennikov, Vladimir I.Nekorkin Dynamics of spiking map-based neural networks in problems of supervised learning. — Communications in Nonlinear Science and Numerical Simulation, 2020, vol. 90, P. 105399](https://www.sciencedirect.com/science/article/abs/pii/S1007570420302318?via%3Dihub)

<details>
    <summary>Abstract</summary>

Recurrent networks of artificial spiking neurons trained to perform target functions are a perspective tool for understanding dynamic principles of information processing in computational neuroscience. Here, we develop a system of this type based on a map-based model of neural activity allowing for producing various biologically relevant regimes. Target signals used to supervisely train the network are sinusoid functions of different frequencies. Impacts of individual neuron dynamics, coupling strength, network size and other key parameters on the learning error are studied. Our findings suggest, among others, that firing rate heterogeneity as well as mixing of spiking and nonspiking regimes of neurons comprising the network can improve its performance for a wider range of target frequencies. At a single neuron activity level, successful training gives rise to well separated domains with qualitatively different dynamics. 
</details>

