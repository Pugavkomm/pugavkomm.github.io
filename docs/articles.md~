# Articles

## Review

* [4.	Maslennikov O V, Pugavko M M, Shchapin D S, Nekorkin V I "Nonlinear dynamics and machine learning of recurrent spiking neural networks" Phys. Usp. 65 1020–1038 (2022)](https://ufn.ru/en/articles/2022/10/b/)

<details>
    <summary>Abstract</summary>

The review describes the main results in the field of design and analysis of recurrent spiking neural networks for modeling functional brain networks. Key terms and definitions from the field of machine learning are given. The main approaches to the construction and study of spiking and rate neural networks trained to perform specific cognitive functions are shown. The modern hardware neuromorphic systems that imitate the information processing by the brain are described. The principles of nonlinear dynamics are discussed, which make it possible to identify the mechanisms for performing target tasks by neural networks.
</details>

## Work

* [M. M. Pugavko, O. V. Maslennikov, V. I. Nekorkin. Dynamics of a network of map-based model neurons for supervised learning of a reservoir computing system. — Izvestiya VUZ. Applied Nonlinear Dynamics 2020. V. 28, N. 1. PP. 77-89](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=ivp&paperid=357&option_lang=eng)

<details>
    <summary> Abstract </summary>

The purpose of this work is to develop a reservoir computing system that contains a network of model neurons with discrete time, and to study the characteristics of the system when it is trained to autonomously generate a harmonic target signal. Methods of work include approaches of nonlinear dynamics (phase space analysis depending on parameters), machine learning (reservoir computing, supervised error minimization) and computer modeling (implementation of numerical algorithms, plotting of characteristics and diagrams). Results. A reservoir computing system based on a network of coupled discrete model neurons was constructed, and the possibility of its supervised training in generating the target signal using the controlled error minimization method FORCE was demonstrated. It has been found that with increasing network size, the mean square error of learning decreases. The dynamic regimes arising at the level of individual activity of intra-reservoir neurons at various stages of training are studied. It is shown that in the process of training, the network-reservoir transits from the state of space-time disorder to the state with regular clusters of spiking activity. The optimal values of the coupling coefficients and the parameters of the intrinsic dynamics of neurons corresponding to the minimum learning error were found. Conclusion. A new reservoir computing system is proposed in the work, the basic unit of which is the Courbage–Nekorkin discrete-time model neuron. The advantage of a network based on such a spiking neuron model is that the model is specified in the form of a mapping, therefore, there is no need to perform an integration operation. The proposed system has shown its effectiveness in training autonomous generation of a harmonic function, as well as for a number of other target functions.
</details>

* [Mechislav M.Pugavko, Oleg V.Maslennikov, Vladimir I.Nekorkin Dynamics of spiking map-based neural networks in problems of supervised learning. — Communications in Nonlinear Science and Numerical Simulation, 2020, vol. 90, P. 105399](https://www.sciencedirect.com/science/article/abs/pii/S1007570420302318?via%3Dihub)

<details>
    <summary>Abstract</summary>

Recurrent networks of artificial spiking neurons trained to perform target functions are a perspective tool for understanding dynamic principles of information processing in computational neuroscience. Here, we develop a system of this type based on a map-based model of neural activity allowing for producing various biologically relevant regimes. Target signals used to supervisely train the network are sinusoid functions of different frequencies. Impacts of individual neuron dynamics, coupling strength, network size and other key parameters on the learning error are studied. Our findings suggest, among others, that firing rate heterogeneity as well as mixing of spiking and nonspiking regimes of neurons comprising the network can improve its performance for a wider range of target frequencies. At a single neuron activity level, successful training gives rise to well separated domains with qualitatively different dynamics.
</details>

* М.М. Пугавко, О.В. Масленников, В.И. Некоркин Динамика рекуррентной спайковой нейронной сети в задаче двухальтернативного выбора // Изв. вузов. Радиофизика (В
печати).
