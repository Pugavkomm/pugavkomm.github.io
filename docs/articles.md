# Статьи 
***
* [Пугавко Мечислав Мечиславович, Масленников Олег Владимирович, Некоркин Владимир Исаакович Динамика сети дискретных модельных нейронов при контролируемом обучении системы резервуарных вычислений. — Известия вузов. ПНД. 2020. Т. 28, вып. 1. С. 77-89, 2020, том 28, № 1, С. 77-89](https://andjournal.sgu.ru/ru/articles/dinamika-seti-diskretnyh-modelnyh-neyronov-pri-kontroliruemom-obuchenii-sistemy)

### Аннотация:

Цель настоящей работы состоит в построении системы резервуарных вычислений, которая содержит сеть модельных нейронов с дискретным временем, и изучении характеристик системы при её обучении автономно генерировать гармонический целевой сигнал. Методы работы включают в себя подходы нелинейной динамики (анализ фазового пространства в зависимости от параметров), машинного обучения (резервуарные вычисления, контролируемая минимизация ошибки) и компьютерного моделирования (реализация численного алгоритма, построение характеристик и диаграмм). Результаты. Построена система резервуарных вычислений на основе сети связанных дискретных модельных нейронов, показана возможность её контролируемого обучения генерации целевого сигнала с помощью метода контролируемой минимизации ошибки FORCE. Установлено, что с ростом размера сети среднеквадратичная ошибка обучения снижается. Исследованы динамические режимы, возникающие на уровне индивидуальной активности внутрирезервуарных нейронов на различных стадиях обучения. Показано, что в процессе обучения сеть-резервуар переходит из состояния пространственно-временного беспорядка в состояние, когда в сети-резервуаре существуют регулярные кластеры спайковой активности. Найдены оптимальные значения коэффициентов связи и параметров собственной динамики нейронов, соответствующие минимальной ошибке обучения. Заключение. В работе предложена новая система резервуарных вычислений, базовой единицей которой является дискретный модельный нейрон Курбажа–Некоркина. Преимущество сети, основанной на такой модели спайкового нейрона, заключается в том, что модель задается в виде точечного отображения, следовательно, нет необходимости производить операцию интегрирования. Предложенная система показала свою эффективность при обучении автономной генерации гармонической функции, а также для ряда других целевых функций.
***
* [Mechislav M.Pugavko, Oleg V.Maslennikov, Vladimir I.Nekorkin Dynamics of spiking map-based neural networks in problems of supervised learning. — Communications in Nonlinear Science and Numerical Simulation, 2020, vol. 90, P. 105399](https://www.sciencedirect.com/science/article/abs/pii/S1007570420302318?via%3Dihub)

### Аннотация: 
Recurrent networks of artificial spiking neurons trained to perform target functions are a perspective tool for understanding dynamic principles of information processing in computational neuroscience. Here, we develop a system of this type based on a map-based model of neural activity allowing for producing various biologically relevant regimes. Target signals used to supervisely train the network are sinusoid functions of different frequencies. Impacts of individual neuron dynamics, coupling strength, network size and other key parameters on the learning error are studied. Our findings suggest, among others, that firing rate heterogeneity as well as mixing of spiking and nonspiking regimes of neurons comprising the network can improve its performance for a wider range of target frequencies. At a single neuron activity level, successful training gives rise to well separated domains with qualitatively different dynamics. 
***
